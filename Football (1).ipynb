{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i9RL_3ygZWxx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXtwMBqgbPyq",
        "outputId": "6e396f33-94cb-4b29-c6e5-1c9a4a42014d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# File paths in Google Drive\n",
        "events_file_path = '/content/drive/MyDrive/BS_Project/events.csv'\n",
        "ginf_file_path = '/content/drive/MyDrive/BS_Project/ginf.csv'\n",
        "\n",
        "# Load datasets\n",
        "events_data = pd.read_csv(events_file_path)\n",
        "ginf_data = pd.read_csv(ginf_file_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH_WzKZJSbZ-"
      },
      "outputs": [],
      "source": [
        "# Display basic information about events_data\n",
        "print(events_data.info())\n",
        "\n",
        "# Display basic information about match_data\n",
        "print(ginf_data.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxJflIukUu1V"
      },
      "outputs": [],
      "source": [
        "# Check for duplicate rows\n",
        "duplicates = events_data.duplicated()\n",
        "dupli=ginf_data.duplicated()\n",
        "# Print the number of duplicate rows\n",
        "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
        "print(f\"Number of duplicate rows: {dupli.sum()}\")\n",
        "\n",
        "# Remove duplicate rows\n",
        "#events_data = events_data.drop_duplicates()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNx77kHFL0gm"
      },
      "outputs": [],
      "source": [
        "missing_matches = ginf_data[~ginf_data['id_odsp'].isin(events_data['id_odsp'])]\n",
        "print(\"Match IDs with no corresponding events:\")\n",
        "print(missing_matches[['id_odsp', 'date', 'league', 'ht', 'at']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KQU4eVvNziC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Sort the missing matches by country\n",
        "sorted_missing_matches = missing_matches.sort_values(by='country')\n",
        "\n",
        "# Display the sorted missing matches\n",
        "print(\"Matches in ginf.csv not present in events.csv, sorted by country:\")\n",
        "print(sorted_missing_matches[['id_odsp', 'date', 'league', 'ht', 'at', 'country']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZJUvCGdSS1M"
      },
      "outputs": [],
      "source": [
        "# Convert 'date' column to datetime format\n",
        "missing_matches['date'] = pd.to_datetime(missing_matches['date'])\n",
        "\n",
        "# Extract the academic year (August of first year to May of second year)\n",
        "def extract_academic_year(date):\n",
        "    if date.month >= 8:\n",
        "        return date.year\n",
        "    else:\n",
        "        return date.year - 1\n",
        "\n",
        "missing_matches['academic_year'] = missing_matches['date'].apply(extract_academic_year)\n",
        "\n",
        "# Count missing rows for each country and academic year\n",
        "missing_counts = missing_matches.groupby(['country', 'academic_year']).size().reset_index(name='missing_count')\n",
        "\n",
        "# Display the missing counts\n",
        "print(\"Number of missing rows for each country and academic year:\")\n",
        "print(missing_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBASSdZGW_5m",
        "outputId": "0348cc5d-b466-4cf1-ecb1-3f0b108c96ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of distinct id_odsp linked with ginf.csv, grouped by country and academic year:\n",
            "    country  academic_year  distinct_id_count\n",
            "0   england           2013                320\n",
            "1   england           2014                380\n",
            "2   england           2015                379\n",
            "3   england           2016                220\n",
            "4    france           2011                368\n",
            "5    france           2012                373\n",
            "6    france           2013                378\n",
            "7    france           2014                380\n",
            "8    france           2015                369\n",
            "9    france           2016                208\n",
            "10  germany           2011                294\n",
            "11  germany           2012                305\n",
            "12  germany           2013                269\n",
            "13  germany           2014                290\n",
            "14  germany           2015                297\n",
            "15  germany           2016                153\n",
            "16    italy           2011                362\n",
            "17    italy           2012                379\n",
            "18    italy           2013                379\n",
            "19    italy           2014                379\n",
            "20    italy           2015                370\n",
            "21    italy           2016                207\n",
            "22    spain           2011                355\n",
            "23    spain           2012                379\n",
            "24    spain           2013                380\n",
            "25    spain           2014                342\n",
            "26    spain           2015                370\n",
            "27    spain           2016                189\n"
          ]
        }
      ],
      "source": [
        "# Merge ginf_data and events_data based on id_odsp\n",
        "merged_data = pd.merge(ginf_data, events_data, on='id_odsp', how='inner')\n",
        "\n",
        "# Convert 'date' column to datetime format\n",
        "merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
        "\n",
        "# Extract the academic year (August of first year to May of second year)\n",
        "def extract_academic_year(date):\n",
        "    if date.month >= 8:\n",
        "        return date.year\n",
        "    else:\n",
        "        return date.year - 1\n",
        "\n",
        "merged_data['academic_year'] = merged_data['date'].apply(extract_academic_year)\n",
        "\n",
        "# Get the number of distinct id_odsp grouped by country and academic year\n",
        "distinct_id_counts = merged_data.groupby(['country', 'academic_year'])['id_odsp'].nunique().reset_index(name='distinct_id_count')\n",
        "\n",
        "# Display the results\n",
        "print(\"Number of distinct id_odsp linked with ginf.csv, grouped by country and academic year:\")\n",
        "print(distinct_id_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTMZnKaZE_8W"
      },
      "outputs": [],
      "source": [
        "# Filter the merged dataset for the chosen country and league for the year 2015\n",
        "chosen_country = \"france\"\n",
        "chosen_year = 2015\n",
        "\n",
        "# filtering\n",
        "filtered_data = merged_data[(merged_data['country'] == chosen_country) & (merged_data['season'].astype(str).str.contains(str(chosen_year)))]\n",
        "\n",
        "# Display the filtered data\n",
        "print(filtered_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE63TpEOIbcB"
      },
      "outputs": [],
      "source": [
        "# Creating correaltion matrix\n",
        "correlation_matrix = filtered_data.corr()\n",
        "\n",
        "# Display the correlation matrix\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP4Adf2jJJOG"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot correlation matrix heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-z4O2zmTRahW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb48b161-5805-4409-a6ad-acb48e88304f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        match_id time_interval  relative_team_strength assists_home  \\\n",
            "0      00QH2XdM/           0-3                0.182953            0   \n",
            "1      00QH2XdM/           3-6                0.182953            1   \n",
            "2      00QH2XdM/           6-9                0.182953            0   \n",
            "3      00QH2XdM/          9-12                0.182953            0   \n",
            "4      00QH2XdM/         12-15                0.182953            0   \n",
            "...          ...           ...                     ...          ...   \n",
            "11395  zwyvizbA/         75-78                0.130899            0   \n",
            "11396  zwyvizbA/         78-81                0.130899            1   \n",
            "11397  zwyvizbA/         81-84                0.130899            0   \n",
            "11398  zwyvizbA/         84-87                0.130899            0   \n",
            "11399  zwyvizbA/         87-90                0.130899            0   \n",
            "\n",
            "      assists_away shots_home shots_away shots_on_target_home  \\\n",
            "0                0          0          0                    0   \n",
            "1                0          1          0                    0   \n",
            "2                0          0          1                    0   \n",
            "3                0          1          0                    0   \n",
            "4                0          2          0                    0   \n",
            "...            ...        ...        ...                  ...   \n",
            "11395            1          0          1                    0   \n",
            "11396            1          1          1                    0   \n",
            "11397            0          0          0                    0   \n",
            "11398            0          1          0                    0   \n",
            "11399            1          0          1                    0   \n",
            "\n",
            "      shots_on_target_away Corner_home  ... Red card_away Substitution_away  \\\n",
            "0                        0           1  ...             0                 0   \n",
            "1                        1           0  ...             0                 0   \n",
            "2                        0           0  ...             0                 0   \n",
            "3                        1           0  ...             0                 0   \n",
            "4                        0           0  ...             0                 0   \n",
            "...                    ...         ...  ...           ...               ...   \n",
            "11395                    1           0  ...             0                 0   \n",
            "11396                    0           0  ...             0                 0   \n",
            "11397                    0           0  ...             0                 1   \n",
            "11398                    0           0  ...             0                 0   \n",
            "11399                    0           0  ...             0                 0   \n",
            "\n",
            "      Free kick won_away Offside_away Hand ball_away Penalty conceded_away  \\\n",
            "0                      0            0              0                     0   \n",
            "1                      2            0              1                     0   \n",
            "2                      1            0              0                     0   \n",
            "3                      0            0              1                     0   \n",
            "4                      0            0              0                     0   \n",
            "...                  ...          ...            ...                   ...   \n",
            "11395                  0            0              1                     0   \n",
            "11396                  0            0              0                     0   \n",
            "11397                  0            0              0                     0   \n",
            "11398                  0            0              0                     0   \n",
            "11399                  0            0              0                     0   \n",
            "\n",
            "      Own goal_home Own goal_away fthg ftag  \n",
            "0                 0             0    3    2  \n",
            "1                 0             0    3    2  \n",
            "2                 0             0    3    2  \n",
            "3                 0             0    3    2  \n",
            "4                 0             0    3    2  \n",
            "...             ...           ...  ...  ...  \n",
            "11395             0             0    0    4  \n",
            "11396             0             0    0    4  \n",
            "11397             0             0    0    4  \n",
            "11398             0             0    0    4  \n",
            "11399             0             0    0    4  \n",
            "\n",
            "[11400 rows x 33 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Filter the dataset for the chosen country, league, and season\n",
        "chosen_country = \"france\"\n",
        "chosen_year = 2015\n",
        "filtered_data = merged_data[(merged_data['country'] == chosen_country) & (merged_data['season'].astype(str).str.contains(str(chosen_year)))]\n",
        "\n",
        "# Define the time intervals (every 3 minutes)\n",
        "time_intervals = list(range(0, 91, 3))  # Assuming matches are 90 minutes long\n",
        "\n",
        "# Define event type mappings\n",
        "event_type_mapping = {\n",
        "    2: 'Corner',\n",
        "    3: 'Foul',\n",
        "    4: 'Yellow card',\n",
        "    5: 'Second yellow card',\n",
        "    6: 'Red card',\n",
        "    7: 'Substitution',\n",
        "    8: 'Free kick won',\n",
        "    9: 'Offside',\n",
        "    10: 'Hand ball',\n",
        "    11: 'Penalty conceded',\n",
        "}\n",
        "\n",
        "# Create an empty DataFrame to store the results\n",
        "columns = ['match_id', 'time_interval', 'relative_team_strength', 'assists_home', 'assists_away', 'shots_home', 'shots_away', 'shots_on_target_home', 'shots_on_target_away']\n",
        "columns += [f'{event}_home' for event in event_type_mapping.values()] + [f'{event}_away' for event in event_type_mapping.values()]\n",
        "columns += ['Own goal_home', 'Own goal_away', 'fthg', 'ftag']  # Include full-time goals\n",
        "result_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "# Loop through each match in the filtered dataset\n",
        "for match_id, match_data in filtered_data.groupby('id_odsp'):\n",
        "    # Get full-time goals for the current match\n",
        "    full_time_home_goals = match_data['fthg'].iloc[0]\n",
        "    full_time_away_goals = match_data['ftag'].iloc[0]\n",
        "\n",
        "    # Initialize an empty DataFrame to store match data\n",
        "    match_rows = []\n",
        "\n",
        "    # Loop through each time interval\n",
        "    for i in range(len(time_intervals) - 1):\n",
        "        start_time = time_intervals[i]\n",
        "        end_time = time_intervals[i + 1]\n",
        "        interval_label = f\"{start_time}-{end_time}\"\n",
        "\n",
        "        # Calculate relative team strength for the current match\n",
        "        home_team = match_data['ht'].iloc[0]\n",
        "        away_team = match_data['at'].iloc[0]\n",
        "        home_strength = relative_strength_home.get(home_team, 0)\n",
        "        away_strength = relative_strength_away.get(away_team, 0)\n",
        "        relative_team_strength = home_strength - away_strength\n",
        "\n",
        "        # Count number of assists for home and away teams in the current interval\n",
        "        assists_home = len(match_data[(match_data['event_type2'] == 12) & (match_data['side'] == 1) & (match_data['time'] >= start_time) & (match_data['time'] < end_time)])\n",
        "        assists_away = len(match_data[(match_data['event_type2'] == 12) & (match_data['side'] == 2) & (match_data['time'] >= start_time) & (match_data['time'] < end_time)])\n",
        "\n",
        "        # Count number of shots for home and away teams in the current interval\n",
        "        shots_home = len(match_data[(match_data['event_type'] == 1) & (match_data['side'] == 1) & (match_data['time'] >= start_time) & (match_data['time'] < end_time)])\n",
        "        shots_away = len(match_data[(match_data['event_type'] == 1) & (match_data['side'] == 2) & (match_data['time'] >= start_time) & (match_data['time'] < end_time)])\n",
        "\n",
        "        # Count number of shots on target for home and away teams in the current interval\n",
        "        shots_on_target_home = len(match_data[(match_data['event_type'] == 10) & (match_data['side'] == 1) & (match_data['time'] >= start_time) & (match_data['time'] < end_time)])\n",
        "        shots_on_target_away = len(match_data[(match_data['event_type'] == 10) & (match_data['side'] == 2) & (match_data['time'] >= start_time) & (match_data['time'] < end_time)])\n",
        "\n",
        "        # Count events for home and away teams in the current interval\n",
        "        events_home = {event: len(match_data[(match_data['event_type'] == code) & (match_data['side'] == 1) & (match_data['time'] >= start_time) & (match_data['time'] < end_time)]) for code, event in event_type_mapping.items()}\n",
        "        events_away = {event: len(match_data[(match_data['event_type'] == code) & (match_data['side'] == 2) & (match_data['time'] >= start_time) & (match_data['time'] < end_time)]) for code, event in event_type_mapping.items()}\n",
        "\n",
        "        # Count Own goals for home and away teams in the current interval\n",
        "        own_goals_home = len(match_data[(match_data['event_type2'] == 15) & (match_data['side'] == 1) & (match_data['time'] >= start_time) & (match_data['time'] < end_time)])\n",
        "        own_goals_away = len(match_data[(match_data['event_type2'] == 15) & (match_data['side'] == 2) & (match_data['time'] >= start_time) & (match_data['time'] < end_time)])\n",
        "\n",
        "        # Append the match data to the list of match rows\n",
        "        match_rows.append([match_id, interval_label, relative_team_strength, assists_home, assists_away, shots_home, shots_away, shots_on_target_home, shots_on_target_away] + list(events_home.values()) + list(events_away.values()) + [own_goals_home, own_goals_away, full_time_home_goals, full_time_away_goals])\n",
        "\n",
        "    # Concatenate the match rows to the result DataFrame\n",
        "    result_df = pd.concat([result_df, pd.DataFrame(match_rows, columns=result_df.columns)], ignore_index=True)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(result_df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6SC0qxgK-YU"
      },
      "outputs": [],
      "source": [
        "# Define a function to determine the winner of each match interval and create a binary target variable\n",
        "def determine_winner_binary(row):\n",
        "    if row['fthg'] > row['ftag']:\n",
        "        return 1  # Home team wins\n",
        "    elif row['fthg'] < row['ftag']:\n",
        "        return -1  # Away team wins\n",
        "    else:\n",
        "        return 0  # Draw\n",
        "\n",
        "# Apply the function to create the binary target variable\n",
        "result_df['target_variable'] = result_df.apply(determine_winner_binary, axis=1)\n",
        "\n",
        "# Splitting data into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(result_df.drop(columns=['match_id', 'target_variable']), result_df['target_variable'], test_size=0.55, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5455, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxPdm2Gstzyk",
        "outputId": "28aa6984-50cd-4d54-bc5b-c16a8c8efa28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train_preprocessed: (5129, 31, 1)\n",
            "Shape of X_val_preprocessed: (2850, 31, 1)\n",
            "Shape of X_test_preprocessed: (3421, 31, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Exclude the Match ID Column\n",
        "X_train = X_train.iloc[:, 1:]\n",
        "X_val = X_val.iloc[:, 1:]\n",
        "X_test = X_test.iloc[:, 1:]\n",
        "\n",
        "# Convert Interval Column to Float\n",
        "def preprocess_interval_column(data):\n",
        "    interval_values = data[:, 0].astype(str)\n",
        "    start_values = []\n",
        "    end_values = []\n",
        "    for interval in interval_values:\n",
        "        if '-' in interval:\n",
        "            start, end = interval.split('-')\n",
        "            if start.isnumeric() and end.isnumeric():\n",
        "                start_values.append(float(start))\n",
        "                end_values.append(float(end))\n",
        "            else:\n",
        "                start_values.append(np.nan)\n",
        "                end_values.append(np.nan)\n",
        "        else:\n",
        "            if interval.isnumeric():\n",
        "                start_values.append(float(interval))\n",
        "                end_values.append(float(interval))\n",
        "            else:\n",
        "                start_values.append(np.nan)\n",
        "                end_values.append(np.nan)\n",
        "\n",
        "    start_values = np.nan_to_num(start_values)\n",
        "    end_values = np.nan_to_num(end_values)\n",
        "    interval_values = (start_values + end_values) / 2.0\n",
        "    interval_values = np.round(interval_values).astype(float)\n",
        "    data[:, 0] = interval_values\n",
        "    return data\n",
        "\n",
        "# Preprocess the data\n",
        "def preprocess_data(data):\n",
        "    # Apply interval preprocessing\n",
        "    data = preprocess_interval_column(data)\n",
        "\n",
        "    # Reshape the data\n",
        "    data = np.expand_dims(data, axis=-1)  # Add a new axis for the LSTM input\n",
        "\n",
        "    return data\n",
        "\n",
        "# Preprocess the data\n",
        "X_train_preprocessed = preprocess_data(X_train.values)\n",
        "X_val_preprocessed = preprocess_data(X_val.values)\n",
        "X_test_preprocessed = preprocess_data(X_test.values)\n",
        "\n",
        "# Print the shapes of preprocessed data\n",
        "print(\"Shape of X_train_preprocessed:\", X_train_preprocessed.shape)\n",
        "print(\"Shape of X_val_preprocessed:\", X_val_preprocessed.shape)\n",
        "print(\"Shape of X_test_preprocessed:\", X_test_preprocessed.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9D4ZG5zvnVr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert the target variables to numpy arrays\n",
        "y_train_preprocessed = y_train.values\n",
        "y_val_preprocessed = y_val.values\n",
        "y_test_preprocessed = y_test.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzsTEX0Ju9MG",
        "outputId": "54bf1a19-8832-4833-b37a-e4540d934146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "161/161 [==============================] - 6s 22ms/step - loss: 0.3179 - val_loss: 0.1202\n",
            "Epoch 2/10\n",
            "161/161 [==============================] - 3s 18ms/step - loss: 0.1110 - val_loss: 0.0911\n",
            "Epoch 3/10\n",
            "161/161 [==============================] - 4s 25ms/step - loss: 0.0828 - val_loss: 0.0624\n",
            "Epoch 4/10\n",
            "161/161 [==============================] - 3s 17ms/step - loss: 0.0504 - val_loss: 0.0361\n",
            "Epoch 5/10\n",
            "161/161 [==============================] - 3s 17ms/step - loss: 0.0251 - val_loss: 0.0174\n",
            "Epoch 6/10\n",
            "161/161 [==============================] - 3s 17ms/step - loss: 0.0130 - val_loss: 0.0104\n",
            "Epoch 7/10\n",
            "161/161 [==============================] - 4s 23ms/step - loss: 0.0092 - val_loss: 0.0076\n",
            "Epoch 8/10\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 0.0073 - val_loss: 0.0064\n",
            "Epoch 9/10\n",
            "161/161 [==============================] - 3s 18ms/step - loss: 0.0059 - val_loss: 0.0055\n",
            "Epoch 10/10\n",
            "161/161 [==============================] - 3s 17ms/step - loss: 0.0052 - val_loss: 0.0043\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 0.0042\n",
            "Test Loss: 0.004214517306536436\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Convert input arrays to float32 data type\n",
        "X_train_preprocessed = np.asarray(X_train_preprocessed).astype(np.float32)\n",
        "y_train_preprocessed = np.asarray(y_train_preprocessed).astype(np.float32)\n",
        "X_val_preprocessed = np.asarray(X_val_preprocessed).astype(np.float32)\n",
        "y_val_preprocessed = np.asarray(y_val_preprocessed).astype(np.float32)\n",
        "X_test_preprocessed = np.asarray(X_test_preprocessed).astype(np.float32)  # Convert test input data\n",
        "y_test_preprocessed = np.asarray(y_test_preprocessed).astype(np.float32)  # Convert test target data\n",
        "\n",
        "# Define the LSTM model architecture\n",
        "model = Sequential([\n",
        "    LSTM(units=64, input_shape=(X_train_preprocessed.shape[1], X_train_preprocessed.shape[2])),\n",
        "    Dense(units=1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_preprocessed, y_train_preprocessed, epochs=10, batch_size=32, validation_data=(X_val_preprocessed, y_val_preprocessed), verbose=1)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss = model.evaluate(X_test_preprocessed, y_test_preprocessed)\n",
        "print(\"Test Loss:\", loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5ESw-Pn3PBa",
        "outputId": "7a27ff8b-29b1-4a67-bdd9-594ffbdc73ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 1s 6ms/step\n",
            "Accuracy: 0.7115789473684211\n",
            "Precision: 0.4819060463025399\n",
            "Recall: 0.6666666666666666\n",
            "F1 Score: 0.5388681592039801\n",
            "Confusion Matrix:\n",
            "[[   0  822    0]\n",
            " [   0  661    0]\n",
            " [   0    0 1367]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Predictions on validation set\n",
        "y_val_pred_probs = model.predict(X_val_preprocessed)\n",
        "\n",
        "# Adjust threshold\n",
        "threshold = 0.5\n",
        "y_val_pred = (y_val_pred_probs > threshold).astype(int)\n",
        "\n",
        "# Flatten predictions to 1D array\n",
        "y_val_pred = y_val_pred.flatten()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_val_preprocessed, y_val_pred)\n",
        "precision = precision_score(y_val_preprocessed, y_val_pred, average='macro', zero_division=0)\n",
        "recall = recall_score(y_val_preprocessed, y_val_pred, average='macro')\n",
        "f1 = f1_score(y_val_preprocessed, y_val_pred, average='macro')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_val_preprocessed, y_val_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUGXMwibMsQG",
        "outputId": "0b8e67d1-43fc-46ae-e341-410cee3babb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - 1s 6ms/step\n",
            "33/33 [==============================] - 1s 6ms/step\n",
            "33/33 [==============================] - 1s 6ms/step\n",
            "33/33 [==============================] - 1s 8ms/step\n",
            "33/33 [==============================] - 1s 7ms/step\n",
            "Mean Accuracy: 0.704813388484762\n",
            "Mean Precision: 0.4790368511488229\n",
            "Mean Recall: 0.6666666666666666\n",
            "Mean F1 Score: 0.5360905160394231\n",
            "Mean Confusion Matrix:\n",
            "[[  0.  302.8   0. ]\n",
            " [  0.  235.    0. ]\n",
            " [  0.    0.  488. ]]\n",
            "Standard Deviation of Accuracy: 0.010908989657652548\n",
            "Standard Deviation of Precision: 0.002787760628284027\n",
            "Standard Deviation of Recall: 0.0\n",
            "Standard Deviation of F1 Score: 0.0026961569395212047\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "\n",
        "\n",
        "# Convert input arrays to float32 data type\n",
        "X_train = np.asarray(X_train).astype(np.float32)\n",
        "y_train = np.asarray(y_train).astype(np.float32)\n",
        "\n",
        "# Define the LSTM model architecture\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        LSTM(units=64, input_shape=(X_train.shape[1], 1)),\n",
        "        Dense(units=1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store evaluation metrics for each fold\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "conf_matrices = []\n",
        "\n",
        "# Perform cross-validation\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Create and train the model on the current fold\n",
        "    model = create_model()\n",
        "    model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "    # Predict on the validation fold\n",
        "    y_val_pred_probs = model.predict(X_val_fold)\n",
        "\n",
        "    # Adjust threshold\n",
        "    threshold = 0.5\n",
        "    y_val_pred = (y_val_pred_probs > threshold).astype(int)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    precision = precision_score(y_val_fold, y_val_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val_fold, y_val_pred, average='macro')\n",
        "    f1 = f1_score(y_val_fold, y_val_pred, average='macro')\n",
        "    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n",
        "\n",
        "    # Append evaluation metrics to lists\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "    conf_matrices.append(conf_matrix)\n",
        "\n",
        "# Calculate mean and standard deviation of evaluation metrics\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "mean_conf_matrix = np.mean(conf_matrices, axis=0)\n",
        "\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Print mean evaluation metrics and mean confusion matrix\n",
        "print(\"Mean Accuracy:\", mean_accuracy)\n",
        "print(\"Mean Precision:\", mean_precision)\n",
        "print(\"Mean Recall:\", mean_recall)\n",
        "print(\"Mean F1 Score:\", mean_f1)\n",
        "print(\"Mean Confusion Matrix:\")\n",
        "print(mean_conf_matrix)\n",
        "\n",
        "# Print standard deviation of evaluation metrics\n",
        "print(\"Standard Deviation of Accuracy:\", std_accuracy)\n",
        "print(\"Standard Deviation of Precision:\", std_precision)\n",
        "print(\"Standard Deviation of Recall:\", std_recall)\n",
        "print(\"Standard Deviation of F1 Score:\", std_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjXF5qxP1N2E"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualization of Evaluation Metrics\n",
        "evaluation_metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "mean_scores = [mean_accuracy, mean_precision, mean_recall, mean_f1]\n",
        "std_scores = [std_accuracy, std_precision, std_recall, std_f1]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(evaluation_metrics, mean_scores, yerr=std_scores, capsize=5, color='skyblue')\n",
        "plt.title('Mean Evaluation Metrics with Standard Deviation')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# Visualization of Mean Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(mean_conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.title('Mean Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Model Architecture Visualization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8RIbJgGsMLl",
        "outputId": "57853a8f-cb23-45f4-e7b6-1c5d2d2d7be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        match_id time_interval  relative_team_strength assists_home  \\\n",
            "0      00OX4xFp/           0-3                0.228206            1   \n",
            "1      00OX4xFp/           3-6                0.228206            0   \n",
            "2      00OX4xFp/           6-9                0.228206            0   \n",
            "3      00OX4xFp/          9-12                0.228206            0   \n",
            "4      00OX4xFp/         12-15                0.228206            1   \n",
            "...          ...           ...                     ...          ...   \n",
            "62275  zwyvizbA/         75-78                0.130899            0   \n",
            "62276  zwyvizbA/         78-81                0.130899            1   \n",
            "62277  zwyvizbA/         81-84                0.130899            0   \n",
            "62278  zwyvizbA/         84-87                0.130899            0   \n",
            "62279  zwyvizbA/         87-90                0.130899            0   \n",
            "\n",
            "      assists_away shots_home shots_away shots_on_target_home  \\\n",
            "0                0          1          0                    0   \n",
            "1                0          0          0                    0   \n",
            "2                0          0          0                    0   \n",
            "3                1          0          1                    0   \n",
            "4                0          1          0                    0   \n",
            "...            ...        ...        ...                  ...   \n",
            "62275            1          0          1                    0   \n",
            "62276            1          1          1                    0   \n",
            "62277            0          0          0                    0   \n",
            "62278            0          1          0                    0   \n",
            "62279            1          0          1                    0   \n",
            "\n",
            "      shots_on_target_away Corner_home  ... Red card_away Substitution_away  \\\n",
            "0                        0           0  ...             0                 0   \n",
            "1                        0           0  ...             0                 0   \n",
            "2                        0           0  ...             0                 0   \n",
            "3                        0           0  ...             0                 0   \n",
            "4                        0           1  ...             0                 0   \n",
            "...                    ...         ...  ...           ...               ...   \n",
            "62275                    1           0  ...             0                 0   \n",
            "62276                    0           0  ...             0                 0   \n",
            "62277                    0           0  ...             0                 1   \n",
            "62278                    0           0  ...             0                 0   \n",
            "62279                    0           0  ...             0                 0   \n",
            "\n",
            "      Free kick won_away Offside_away Hand ball_away Penalty conceded_away  \\\n",
            "0                      0            0              0                     0   \n",
            "1                      1            0              0                     0   \n",
            "2                      0            0              0                     0   \n",
            "3                      1            0              0                     0   \n",
            "4                      1            0              0                     0   \n",
            "...                  ...          ...            ...                   ...   \n",
            "62275                  0            0              1                     0   \n",
            "62276                  0            0              0                     0   \n",
            "62277                  0            0              0                     0   \n",
            "62278                  0            0              0                     0   \n",
            "62279                  0            0              0                     0   \n",
            "\n",
            "      Own goal_home Own goal_away fthg ftag  \n",
            "0                 0             0    0    0  \n",
            "1                 0             0    0    0  \n",
            "2                 0             0    0    0  \n",
            "3                 0             0    0    0  \n",
            "4                 0             0    0    0  \n",
            "...             ...           ...  ...  ...  \n",
            "62275             0             0    0    4  \n",
            "62276             0             0    0    4  \n",
            "62277             0             0    0    4  \n",
            "62278             0             0    0    4  \n",
            "62279             0             0    0    4  \n",
            "\n",
            "[62280 rows x 33 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Filter the dataset for the chosen country\n",
        "chosen_country = \"france\"\n",
        "filtered_data = merged_data[merged_data['country'] == chosen_country]\n",
        "\n",
        "# Define the time intervals (every 3 minutes)\n",
        "time_intervals = list(range(0, 91, 3))  # Assuming matches are 90 minutes long\n",
        "\n",
        "# Define event type mappings\n",
        "event_type_mapping = {\n",
        "    2: 'Corner',\n",
        "    3: 'Foul',\n",
        "    4: 'Yellow card',\n",
        "    5: 'Second yellow card',\n",
        "    6: 'Red card',\n",
        "    7: 'Substitution',\n",
        "    8: 'Free kick won',\n",
        "    9: 'Offside',\n",
        "    10: 'Hand ball',\n",
        "    11: 'Penalty conceded',\n",
        "}\n",
        "\n",
        "# Create an empty DataFrame to store the results\n",
        "columns = ['match_id', 'time_interval', 'relative_team_strength', 'assists_home', 'assists_away', 'shots_home', 'shots_away', 'shots_on_target_home', 'shots_on_target_away']\n",
        "columns += [f'{event}_home' for event in event_type_mapping.values()] + [f'{event}_away' for event in event_type_mapping.values()]\n",
        "columns += ['Own goal_home', 'Own goal_away', 'fthg', 'ftag']  # Include full-time goals\n",
        "result_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "# Compute the relative team strength\n",
        "# Count matches won and matches played for each team\n",
        "matches_won_home = filtered_data[filtered_data['fthg'] > filtered_data['ftag']].groupby('ht').size()\n",
        "matches_played_home = filtered_data.groupby('ht').size()\n",
        "matches_won_away = filtered_data[filtered_data['ftag'] > filtered_data['fthg']].groupby('at').size()\n",
        "matches_played_away = filtered_data.groupby('at').size()\n",
        "\n",
        "# Calculate relative team strength for each team\n",
        "relative_strength_home = matches_won_home / matches_played_home\n",
        "relative_strength_away = matches_won_away / matches_played_away\n",
        "\n",
        "# Loop through each match in the filtered dataset\n",
        "for match_id, match_data in filtered_data.groupby('id_odsp'):\n",
        "    # Get full-time goals for the current match\n",
        "    full_time_home_goals = match_data['fthg'].iloc[0]\n",
        "    full_time_away_goals = match_data['ftag'].iloc[0]\n",
        "\n",
        "    # Initialize match rows list to store data for each match\n",
        "    match_rows = []\n",
        "\n",
        "    # Calculate relative team strength for the current match\n",
        "    home_team = match_data['ht'].iloc[0]\n",
        "    away_team = match_data['at'].iloc[0]\n",
        "    home_strength = relative_strength_home.get(home_team, 0)\n",
        "    away_strength = relative_strength_away.get(away_team, 0)\n",
        "    relative_team_strength = home_strength - away_strength\n",
        "\n",
        "    # Loop through each time interval\n",
        "    for i in range(len(time_intervals) - 1):\n",
        "        start_time = time_intervals[i]\n",
        "        end_time = time_intervals[i + 1]\n",
        "        interval_label = f\"{start_time}-{end_time}\"\n",
        "\n",
        "        # Filter data for the current time interval\n",
        "        interval_data = match_data[(match_data['time'] >= start_time) & (match_data['time'] < end_time)]\n",
        "\n",
        "        # Count number of assists for home and away teams in the current interval\n",
        "        assists_home = interval_data[(interval_data['event_type2'] == 12) & (interval_data['side'] == 1)].shape[0]\n",
        "        assists_away = interval_data[(interval_data['event_type2'] == 12) & (interval_data['side'] == 2)].shape[0]\n",
        "\n",
        "        # Count number of shots for home and away teams in the current interval\n",
        "        shots_home = interval_data[(interval_data['event_type'] == 1) & (interval_data['side'] == 1)].shape[0]\n",
        "        shots_away = interval_data[(interval_data['event_type'] == 1) & (interval_data['side'] == 2)].shape[0]\n",
        "\n",
        "        # Count number of shots on target for home and away teams in the current interval\n",
        "        shots_on_target_home = interval_data[(interval_data['event_type'] == 10) & (interval_data['side'] == 1)].shape[0]\n",
        "        shots_on_target_away = interval_data[(interval_data['event_type'] == 10) & (interval_data['side'] == 2)].shape[0]\n",
        "\n",
        "        # Count events for home and away teams in the current interval\n",
        "        events_home = {event: interval_data[(interval_data['event_type'] == code) & (interval_data['side'] == 1)].shape[0] for code, event in event_type_mapping.items()}\n",
        "        events_away = {event: interval_data[(interval_data['event_type'] == code) & (interval_data['side'] == 2)].shape[0] for code, event in event_type_mapping.items()}\n",
        "\n",
        "        # Count Own goals for home and away teams in the current interval\n",
        "        own_goals_home = interval_data[(interval_data['event_type2'] == 15) & (interval_data['side'] == 1)].shape[0]\n",
        "        own_goals_away = interval_data[(interval_data['event_type2'] == 15) & (interval_data['side'] == 2)].shape[0]\n",
        "\n",
        "        # Append the match data to the list of match rows\n",
        "        match_rows.append([match_id, interval_label, relative_team_strength, assists_home, assists_away, shots_home, shots_away, shots_on_target_home, shots_on_target_away] + list(events_home.values()) + list(events_away.values()) + [own_goals_home, own_goals_away, full_time_home_goals, full_time_away_goals])\n",
        "\n",
        "    # Concatenate the match rows to the result DataFrame\n",
        "    result_df = pd.concat([result_df, pd.DataFrame(match_rows, columns=result_df.columns)], ignore_index=True)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(result_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IKoLRltjy8DJ"
      },
      "outputs": [],
      "source": [
        "# Define a function to determine the winner of each match interval and create a binary target variable\n",
        "def determine_winner_binary(row):\n",
        "    if row['fthg'] > row['ftag']:\n",
        "        return 1  # Home team wins\n",
        "    elif row['fthg'] < row['ftag']:\n",
        "        return -1  # Away team wins\n",
        "    else:\n",
        "        return 0  # Draw\n",
        "\n",
        "# Apply the function to create the binary target variable\n",
        "result_df['target_variable'] = result_df.apply(determine_winner_binary, axis=1)\n",
        "\n",
        "# Splitting data into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(result_df.drop(columns=['match_id', 'target_variable']), result_df['target_variable'], test_size=0.55, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5455, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JsURLidzCIj",
        "outputId": "88248b39-fda5-49e7-e9b7-2b4ce4728025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_preprocessed: (28026, 31, 1)\n",
            "Shape of X_val_preprocessed: (15568, 31, 1)\n",
            "Shape of X_test_preprocessed: (18686, 31, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Exclude the Match ID Column\n",
        "X_train = X_train.iloc[:, 1:]\n",
        "X_val = X_val.iloc[:, 1:]\n",
        "X_test = X_test.iloc[:, 1:]\n",
        "\n",
        "# Convert Interval Column to Float\n",
        "def preprocess_interval_column(data):\n",
        "    interval_values = data[:, 0].astype(str)\n",
        "    start_values = []\n",
        "    end_values = []\n",
        "    for interval in interval_values:\n",
        "        if '-' in interval:\n",
        "            start, end = interval.split('-')\n",
        "            if start.isnumeric() and end.isnumeric():\n",
        "                start_values.append(float(start))\n",
        "                end_values.append(float(end))\n",
        "            else:\n",
        "                start_values.append(np.nan)\n",
        "                end_values.append(np.nan)\n",
        "        else:\n",
        "            if interval.isnumeric():\n",
        "                start_values.append(float(interval))\n",
        "                end_values.append(float(interval))\n",
        "            else:\n",
        "                start_values.append(np.nan)\n",
        "                end_values.append(np.nan)\n",
        "\n",
        "    start_values = np.nan_to_num(start_values)\n",
        "    end_values = np.nan_to_num(end_values)\n",
        "    interval_values = (start_values + end_values) / 2.0\n",
        "    interval_values = np.round(interval_values).astype(float)\n",
        "    data[:, 0] = interval_values\n",
        "    return data\n",
        "\n",
        "# Preprocess the data\n",
        "def preprocess_data(data):\n",
        "    # Apply interval preprocessing\n",
        "    data = preprocess_interval_column(data)\n",
        "\n",
        "    # Reshape the data\n",
        "    data = np.expand_dims(data, axis=-1)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Preprocess the data\n",
        "X_train_preprocessed = preprocess_data(X_train.values)\n",
        "X_val_preprocessed = preprocess_data(X_val.values)\n",
        "X_test_preprocessed = preprocess_data(X_test.values)\n",
        "\n",
        "# Print the shapes of preprocessed data\n",
        "print(\"Shape of X_train_preprocessed:\", X_train_preprocessed.shape)\n",
        "print(\"Shape of X_val_preprocessed:\", X_val_preprocessed.shape)\n",
        "print(\"Shape of X_test_preprocessed:\", X_test_preprocessed.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SVZHPDr1zKl7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert the target variables to numpy arrays\n",
        "y_train_preprocessed = y_train.values\n",
        "y_val_preprocessed = y_val.values\n",
        "y_test_preprocessed = y_test.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhkIonzuzOui",
        "outputId": "9c0e5f10-3b8b-4cbf-e9a6-6e472c5ac3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "876/876 [==============================] - 19s 19ms/step - loss: 0.1057 - val_loss: 0.0161\n",
            "Epoch 2/10\n",
            "876/876 [==============================] - 19s 21ms/step - loss: 0.0061 - val_loss: 0.0029\n",
            "Epoch 3/10\n",
            "876/876 [==============================] - 16s 19ms/step - loss: 0.0020 - val_loss: 0.0014\n",
            "Epoch 4/10\n",
            "876/876 [==============================] - 16s 18ms/step - loss: 9.3348e-04 - val_loss: 7.7865e-04\n",
            "Epoch 5/10\n",
            "876/876 [==============================] - 16s 18ms/step - loss: 4.7636e-04 - val_loss: 5.9348e-04\n",
            "Epoch 6/10\n",
            "876/876 [==============================] - 17s 19ms/step - loss: 2.8754e-04 - val_loss: 1.5835e-04\n",
            "Epoch 7/10\n",
            "876/876 [==============================] - 16s 18ms/step - loss: 2.3002e-04 - val_loss: 1.9371e-04\n",
            "Epoch 8/10\n",
            "876/876 [==============================] - 17s 19ms/step - loss: 1.4955e-04 - val_loss: 6.1753e-05\n",
            "Epoch 9/10\n",
            "876/876 [==============================] - 16s 19ms/step - loss: 1.4863e-04 - val_loss: 9.6975e-05\n",
            "Epoch 10/10\n",
            "876/876 [==============================] - 16s 18ms/step - loss: 9.3803e-05 - val_loss: 2.4612e-05\n",
            "584/584 [==============================] - 4s 6ms/step - loss: 2.2880e-05\n",
            "Test Loss: 2.2880431060912088e-05\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Convert input arrays to float32 data type\n",
        "X_train_preprocessed = np.asarray(X_train_preprocessed).astype(np.float32)\n",
        "y_train_preprocessed = np.asarray(y_train_preprocessed).astype(np.float32)\n",
        "X_val_preprocessed = np.asarray(X_val_preprocessed).astype(np.float32)\n",
        "y_val_preprocessed = np.asarray(y_val_preprocessed).astype(np.float32)\n",
        "X_test_preprocessed = np.asarray(X_test_preprocessed).astype(np.float32)  # Convert test input data\n",
        "y_test_preprocessed = np.asarray(y_test_preprocessed).astype(np.float32)  # Convert test target data\n",
        "\n",
        "# Define the LSTM model architecture\n",
        "model = Sequential([\n",
        "    LSTM(units=64, input_shape=(X_train_preprocessed.shape[1], X_train_preprocessed.shape[2])),\n",
        "    Dense(units=1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_preprocessed, y_train_preprocessed, epochs=10, batch_size=32, validation_data=(X_val_preprocessed, y_val_preprocessed), verbose=1)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss = model.evaluate(X_test_preprocessed, y_test_preprocessed)\n",
        "print(\"Test Loss:\", loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUNsoWvd0siZ",
        "outputId": "8f6e28c1-92f8-46e0-d79b-821c638f6ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "487/487 [==============================] - 3s 6ms/step\n",
            "Accuracy: 0.7329779033915724\n",
            "Precision: 0.5016081000595592\n",
            "Recall: 0.6666666666666666\n",
            "F1 Score: 0.5569803952610887\n",
            "Confusion Matrix:\n",
            "[[   0 4157    0]\n",
            " [   0 4238    0]\n",
            " [   0    0 7173]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Predictions on validation set\n",
        "y_val_pred_probs = model.predict(X_val_preprocessed)\n",
        "\n",
        "# Adjust threshold\n",
        "threshold = 0.5\n",
        "y_val_pred = (y_val_pred_probs > threshold).astype(int)\n",
        "\n",
        "# Flatten predictions to 1D array\n",
        "y_val_pred = y_val_pred.flatten()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_val_preprocessed, y_val_pred)\n",
        "precision = precision_score(y_val_preprocessed, y_val_pred, average='macro', zero_division=0)\n",
        "recall = recall_score(y_val_preprocessed, y_val_pred, average='macro')\n",
        "f1 = f1_score(y_val_preprocessed, y_val_pred, average='macro')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_val_preprocessed, y_val_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQgNlAA5011v",
        "outputId": "fbd4352a-73c1-458f-98e5-d77dc18d4df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 1s 6ms/step\n",
            "176/176 [==============================] - 1s 5ms/step\n",
            "176/176 [==============================] - 2s 6ms/step\n",
            "176/176 [==============================] - 1s 6ms/step\n",
            "176/176 [==============================] - 2s 6ms/step\n",
            "Mean Accuracy: 0.7298935924075232\n",
            "Mean Precision: 0.5011150730396066\n",
            "Mean Recall: 0.6666666666666666\n",
            "Mean F1 Score: 0.5565395280187566\n",
            "Mean Confusion Matrix:\n",
            "[[   0.  1514.     0. ]\n",
            " [   0.  1534.4    0. ]\n",
            " [   0.     0.  2556.8]]\n",
            "Standard Deviation of Accuracy: 0.0029731060209175183\n",
            "Standard Deviation of Precision: 0.0016814053038209068\n",
            "Standard Deviation of Recall: 0.0\n",
            "Standard Deviation of F1 Score: 0.0014895854963022463\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "\n",
        "\n",
        "# Convert input arrays to float32 data type\n",
        "X_train = np.asarray(X_train).astype(np.float32)\n",
        "y_train = np.asarray(y_train).astype(np.float32)\n",
        "\n",
        "# Define the LSTM model architecture\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        LSTM(units=64, input_shape=(X_train.shape[1], 1)),\n",
        "        Dense(units=1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store evaluation metrics for each fold\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "conf_matrices = []\n",
        "\n",
        "# Perform cross-validation\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Create and train the model on the current fold\n",
        "    model = create_model()\n",
        "    model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "    # Predict on the validation fold\n",
        "    y_val_pred_probs = model.predict(X_val_fold)\n",
        "\n",
        "    # Adjust threshold\n",
        "    threshold = 0.5\n",
        "    y_val_pred = (y_val_pred_probs > threshold).astype(int)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    precision = precision_score(y_val_fold, y_val_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val_fold, y_val_pred, average='macro')\n",
        "    f1 = f1_score(y_val_fold, y_val_pred, average='macro')\n",
        "    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n",
        "\n",
        "    # Append evaluation metrics to lists\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "    conf_matrices.append(conf_matrix)\n",
        "\n",
        "# Calculate mean and standard deviation of evaluation metrics\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "mean_conf_matrix = np.mean(conf_matrices, axis=0)\n",
        "\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Print mean evaluation metrics and mean confusion matrix\n",
        "print(\"Mean Accuracy:\", mean_accuracy)\n",
        "print(\"Mean Precision:\", mean_precision)\n",
        "print(\"Mean Recall:\", mean_recall)\n",
        "print(\"Mean F1 Score:\", mean_f1)\n",
        "print(\"Mean Confusion Matrix:\")\n",
        "print(mean_conf_matrix)\n",
        "\n",
        "# Print standard deviation of evaluation metrics\n",
        "print(\"Standard Deviation of Accuracy:\", std_accuracy)\n",
        "print(\"Standard Deviation of Precision:\", std_precision)\n",
        "print(\"Standard Deviation of Recall:\", std_recall)\n",
        "print(\"Standard Deviation of F1 Score:\", std_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47TQj9123Y-A"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualization of Evaluation Metrics\n",
        "evaluation_metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "mean_scores = [mean_accuracy, mean_precision, mean_recall, mean_f1]\n",
        "std_scores = [std_accuracy, std_precision, std_recall, std_f1]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(evaluation_metrics, mean_scores, yerr=std_scores, capsize=5, color='skyblue')\n",
        "plt.title('Mean Evaluation Metrics with Standard Deviation')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# Visualization of Mean Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(mean_conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.title('Mean Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Model Architecture Visualization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JM86kmS4nBm"
      },
      "outputs": [],
      "source": [
        "# Bar plot for comparison of different event types\n",
        "event_types = [f'{event}_home' for event in event_type_mapping.values()] + [f'{event}_away' for event in event_type_mapping.values()]\n",
        "event_counts = result_df[event_types].sum()\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=event_counts.index, y=event_counts.values, palette='Set3')\n",
        "plt.title('Comparison of Event Types')\n",
        "plt.xlabel('Event Type')\n",
        "plt.ylabel('Total Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}